{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291a073c",
   "metadata": {},
   "source": [
    "# Functions to train and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37e796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6afbd4",
   "metadata": {},
   "source": [
    "*Get mean of available bikes per station per day for each hour to later compare if the model improves this baseline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9b243a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_bikes_mean_per_day_and_hour(station_id, full_hour_list, weekdays_list):\n",
    "    available_bikes_mean_per_day_and_hour = {}\n",
    "    for weekday in weekdays_list:\n",
    "        available_bikes_mean_per_day_and_hour[weekday] = []\n",
    "        for hour in full_hour_list:\n",
    "            available_bikes_mean_per_hour_of_day = {}\n",
    "            available_bikes_mean_per_hour_of_day[hour] = 0\n",
    "            list_of_unique_availability_values = df_availability_and_weather.loc[(df_availability_and_weather['stationId'] == station_id) & \n",
    "                                                (df_availability_and_weather['weekday'] == weekday) & \n",
    "                                                (df_availability_and_weather['fullHour'] == hour)].availableBikes.value_counts().index.tolist()\n",
    "            \n",
    "            # get mean availablity for current hour being iterated\n",
    "            sum_availability = 0\n",
    "            for number in list_of_unique_availability_values:\n",
    "                sum_availability += number\n",
    "            try:\n",
    "                mean_availability = sum_availability/len(list_of_unique_availability_values)\n",
    "                available_bikes_mean_per_hour_of_day[hour] = mean_availability\n",
    "            except ZeroDivisionError:\n",
    "                print(\"Division by Zero Error:\", station_id, weekday, hour)\n",
    "                break\n",
    "            \n",
    "            # append dict {hour: mean_availability} as a value for each weekday key in the available_bikes_mean_per_day_and_hour dict\n",
    "            available_bikes_mean_per_day_and_hour[weekday].append(available_bikes_mean_per_hour_of_day)\n",
    "            \n",
    "    return {station_id : available_bikes_mean_per_day_and_hour}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71ec6ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_mean_availability_per_day_and_hour(station_id_list, full_hour_list, weekdays_list):\n",
    "    mean_availability = []\n",
    "    for station_id in station_id_list:\n",
    "        mean_availability.append(get_available_bikes_mean_per_day_and_hour(station_id, full_hour_list, weekdays_list))\n",
    "    return mean_availability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64663a4c",
   "metadata": {},
   "source": [
    "### Training a model for each station for each split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8195dfb",
   "metadata": {},
   "source": [
    "*We are building a model per station so each station data needs to be filtered from the original CSV which has data on all stations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b2a682f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get station rows from original csv\n",
    "# returns a dataframe with the rows that have the station_id as value in stationId column\n",
    "def filter_station_data(df, station_id):\n",
    "    station_df = df.loc[(df['stationId'] == station_id)]\n",
    "    return station_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de1624aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our data should already be ordered by default, but just to make sure this function orders everyhting by lastUpdate\n",
    "def order_df_by_lastUpdate(station_df):\n",
    "    station_df_time_ordered = station_df.sort_values(['lastUpdate'])\n",
    "    # need to reset index after sorting\n",
    "    station_df_time_ordered_reset = station_df_time_ordered.reset_index(drop=True)\n",
    "    return station_df_time_ordered_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b520a39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate descriptive features and target feature\n",
    "# returns two dataframes \n",
    "def get_station_features_and_target(station_dataframe_ordered, features):\n",
    "    X = station_dataframe_ordered[features]\n",
    "    y = station_dataframe_ordered.availableBikes\n",
    "    # print(\"\\nDescriptive features in X:\\n\", X)\n",
    "    # print(\"\\nTarget feature in y:\\n\", y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e14147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function splits the station data into training and test for 'n_splits' times and trains a model for each split\n",
    "# returns a dictionary with number of the split as key and the training and test data and model learned as values\n",
    "def split_time_series_data_and_train_model_for_each_split(X, y, number_splits, number_test_size, number_gap):\n",
    "    splits = {}\n",
    "    for i in range(0, number_splits):\n",
    "        splits[f'split_{i+1}'] = {}\n",
    "    \n",
    "    # we can set different test sizes and splits to see the difference in the outcome if we want\n",
    "        # we can also add a gap between train and test data\n",
    "    # test_size defaults to: n_samples // (n_splits + 1) --> so if we want at least 20% of data for test\n",
    "        # n_splits should be max 4 and test_size=None\n",
    "    tscv = TimeSeriesSplit(n_splits=number_splits, test_size=number_test_size, gap=number_gap)\n",
    "    \n",
    "    split_index = 1\n",
    "    \n",
    "    # split data 'n_splits' times\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        \n",
    "        # separate data in training and test data for both descriptive features and target feature\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # store data of the current split in 'splits' dictionary\n",
    "        splits[f'split_{split_index}']['X_train'] = X_train\n",
    "        splits[f'split_{split_index}']['X_test'] = X_test\n",
    "        splits[f'split_{split_index}']['y_train'] = y_train\n",
    "        splits[f'split_{split_index}']['y_test'] = y_test\n",
    "        \n",
    "        # fit the model for the current split on training data\n",
    "        model_for_split = apply_model_to_training_data(X_train, y_train)\n",
    "        \n",
    "        # store the model learned for the current split data in 'splits' dictionary\n",
    "        splits[f'split_{split_index}']['Model'] = model_for_split\n",
    "        split_index += 1\n",
    "        \n",
    "    #print('splits:', splits)\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98884f",
   "metadata": {},
   "source": [
    "*Get the predictions (for each split) and metrics (for each split and the average over all splits) for every station*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40cc99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to predict target feature on data\n",
    "def get_predictions(model_for_station, data):\n",
    "    data_converted_2D_array = data.to_numpy()\n",
    "    predictions = model_for_station.predict(data_converted_2D_array)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ae63df40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted availableBikes values for each split for each station\n",
    "# accepts data as argument --> training data or test data\n",
    "def get_predictions_and_metrics_for_each_split_all_stations(stations_splits_and_models_dict, X_train_or_test_data, y_train_or_test_data):\n",
    "    \n",
    "    if X_train_or_test_data == 'X_train' and y_train_or_test_data == 'y_train':\n",
    "        X_data = 'X_train'\n",
    "        y_data = 'y_train'\n",
    "    elif X_train_or_test_data == 'X_test' and y_train_or_test_data == 'y_test':\n",
    "        X_data = 'X_test'\n",
    "        y_data = 'y_test'\n",
    "        \n",
    "    station_predictions = {}\n",
    "\n",
    "    stations_ids = list(stations_splits_and_models_dict.keys())\n",
    "    for station_id in stations_ids:\n",
    "        station_predictions[station_id] = {}\n",
    "        split_keys = list(stations_splits_and_models_dict[station_id].keys())\n",
    "\n",
    "        # for each station get each split and the model learned for each split and predict on each split\n",
    "        for i in range(1, len(split_keys)):\n",
    "            station_predictions[station_id][split_keys[i]] = {}\n",
    "            \n",
    "            X_split = stations_splits_and_models_dict[station_id][split_keys[i]][X_data]\n",
    "            model_for_X_split = stations_splits_and_models_dict[station_id][split_keys[i]]['Model']\n",
    "            y_split = stations_splits_and_models_dict[station_id][split_keys[i]][y_data]\n",
    "            predictions_on_X_split = get_predictions(model_for_X_split, X_split)\n",
    "\n",
    "            # add data and predictions for each split to the dict\n",
    "            station_predictions[station_id][split_keys[i]][X_data] = X_split\n",
    "            station_predictions[station_id][split_keys[i]][y_data] = y_split\n",
    "            station_predictions[station_id][split_keys[i]]['availability_predictions'] = predictions_on_X_split\n",
    "            \n",
    "            # get metrics of predictions\n",
    "            mae, mse, rmse, r2 = calculate_metrics_of_prediction(y_split, predictions_on_X_split)\n",
    "            station_predictions[station_id][split_keys[i]]['Metrics'] = {}\n",
    "            station_predictions[station_id][split_keys[i]]['Metrics']['MAE'] = mae\n",
    "            station_predictions[station_id][split_keys[i]]['Metrics']['MSE'] = mse\n",
    "            station_predictions[station_id][split_keys[i]]['Metrics']['RMSE'] = rmse\n",
    "            station_predictions[station_id][split_keys[i]]['Metrics']['R2'] = r2\n",
    "    \n",
    "    stations_predictions_with_avg_metrics = add_avg_metrics_over_splits_to_station_dict(station_predictions)\n",
    "            \n",
    "    return stations_predictions_with_avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5012b495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_of_prediction(y_data_actual_values, availability_predictions):\n",
    "    mae = metrics.mean_absolute_error(y_data_actual_values, availability_predictions)\n",
    "    mse = metrics.mean_squared_error(y_data_actual_values, availability_predictions)\n",
    "    rmse = metrics.mean_squared_error(y_data_actual_values, availability_predictions)**0.5\n",
    "    r2 = metrics.r2_score(y_data_actual_values, availability_predictions)\n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a746dd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metric_value_over_splits(values_list):\n",
    "    sum_values = 0\n",
    "    for value in values_list:\n",
    "            sum_values += value\n",
    "    avg_value = sum_values/len(values_list)\n",
    "    return avg_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1eb9ee64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_avg_metrics_over_splits_to_station_dict(predictions_dict):\n",
    "    \n",
    "    for station_key in predictions_dict.keys():\n",
    "        mae_values = []\n",
    "        mse_values = []\n",
    "        rmse_values = []\n",
    "        r2_values = []\n",
    "            \n",
    "        for split_key in predictions_dict[station_key].keys():\n",
    "            split_metrics_dict = predictions_dict[station_key][split_key]['Metrics']\n",
    "             \n",
    "            for metric_key in split_metrics_dict.keys():\n",
    "                if metric_key == 'MAE':\n",
    "                    mae_values.append(split_metrics_dict[metric_key])\n",
    "                if metric_key == 'MSE':\n",
    "                    mse_values.append(split_metrics_dict[metric_key])\n",
    "                if metric_key == 'RMSE':\n",
    "                    rmse_values.append(split_metrics_dict[metric_key])\n",
    "                elif metric_key == 'R2':\n",
    "                    r2_values.append(split_metrics_dict[metric_key])\n",
    "        \n",
    "        \n",
    "        avg_mae = get_average_metric_value_over_splits(mae_values)\n",
    "        avg_mse = get_average_metric_value_over_splits(mse_values)\n",
    "        avg_rmse = get_average_metric_value_over_splits(rmse_values)\n",
    "        avg_r2 = get_average_metric_value_over_splits(r2_values)\n",
    "        \n",
    "        predictions_dict[station_key]['AVG Metrics'] = {'AVG MAE': avg_mae, 'AVG MSE': avg_mse,\n",
    "                                                        'AVG RMSE': avg_rmse, 'AVG R2': avg_r2}\n",
    "    return predictions_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
